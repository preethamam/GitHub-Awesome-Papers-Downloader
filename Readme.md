# Introduction
Downloads the GitHub awesome papers (example: [3D Diffusion Papers](https://github.com/cwchenwang/awesome-3d-diffusion)) in `Section` and `subsection` formats by creating the folders for the same. Formats of the input `papers.txt` and file saving output filenames are provided below:
```
## 2D Diffusion with Pretraining
### Text-to-3D Object Generation
- [DreamFusion: Text-to-3D using 2D Diffusion](https://arxiv.org/abs/2209.14988), Poole et al., Arxiv 2022
- [Magic3D: High-Resolution Text-to-3D Content Creation](https://arxiv.org/abs/2211.10440), Lin et al., Arxiv 2022
### Text-to-3D Scene Generation
- [Text2Room: Extracting Textured 3D Meshes from 2D Text-to-Image Models](https://arxiv.org/abs/2303.11989), HÃ¶llein et al., Arxiv 2023
- [SceneScape: Text-Driven Consistent Scene Generation](https://arxiv.org/abs/2302.01133), Fridman et al., Arxiv 2023
- [Compositional 3D Scene Generation using Locally Conditioned Diffusion](https://arxiv.org/abs/2303.12218), Po and Wetzstein, Arxiv 2023
```

`Required output filename format`: [2023tr-ax] DreamFusion- Text-to-3D using 2D Diffusion.pdf

# Authors
1. Dr. Preetham Manjunatha, Ph.D in Civil Engineering, M.S in Computer Science, M.S in Electrical Engineering and M.S in Civil Engineering, University of Southern California.

2. Aniketh Manjunath ([vma1996](https://github.com/vma1996)), M.S in Computer Science, University of Southern California.

# Feedback
Please rate and provide feedback for the further improvements.



